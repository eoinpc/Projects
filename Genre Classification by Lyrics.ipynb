{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ae89977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from langdetect import detect\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from gensim.models import Word2Vec\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b8c18e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9465</th>\n",
       "      <td>[\"I see the look of evil in your eyes\\nYou've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16621</th>\n",
       "      <td>[\"Some sunny day, baby\\nWhen everything seems ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17852</th>\n",
       "      <td>['[Chorus]\\nThat\\'s word, we pray (Pray, pray)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16903</th>\n",
       "      <td>[\"[Verse 1: Rufus Thomas]\\nTold me that you lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>[\"Know you are a friend of mine, babe you been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>[\"Sometimes I really think\\nI'm going crazy in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18773</th>\n",
       "      <td>[\"[Verse 1]\\nWell, baby used to stay out all n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20074</th>\n",
       "      <td>[\"We were just kids\\nPlayin' in the rain\\nWhen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>[\"You're an anchor, I'm uptight\\nYou're what g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>['Sometimes I wonder… Do you\\nEven recognize t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  lyrics\n",
       "9465   [\"I see the look of evil in your eyes\\nYou've ...\n",
       "16621  [\"Some sunny day, baby\\nWhen everything seems ...\n",
       "17852  ['[Chorus]\\nThat\\'s word, we pray (Pray, pray)...\n",
       "16903  [\"[Verse 1: Rufus Thomas]\\nTold me that you lo...\n",
       "7079   [\"Know you are a friend of mine, babe you been...\n",
       "...                                                  ...\n",
       "8185   [\"Sometimes I really think\\nI'm going crazy in...\n",
       "18773  [\"[Verse 1]\\nWell, baby used to stay out all n...\n",
       "20074  [\"We were just kids\\nPlayin' in the rain\\nWhen...\n",
       "12838  [\"You're an anchor, I'm uptight\\nYou're what g...\n",
       "1858   ['Sometimes I wonder… Do you\\nEven recognize t...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lyrics.csv', sep = '\\t')\n",
    "df.drop('song_id', axis = 1, inplace = True)\n",
    "df.dropna(inplace = True)\n",
    "df = df.sample(10000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a9c70563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(x):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = x['lyrics']\n",
    "    sections = text.split('\\\\n\\\\n')\n",
    "    lyrics = str()\n",
    "    single_text = []\n",
    "    res = {}\n",
    "    \n",
    "    for s in sections:\n",
    "        single_text += [x.lower().replace('(','').replace(')','').translate(translator) \\\n",
    "                        for x in s[s.find(']') + 1:].split('\\\\n') if len(x) > 1]\n",
    "        res['single_text'] =  ' '.join(single_text)\n",
    "        \n",
    "    return pd.Series(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eea53c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9465</th>\n",
       "      <td>i see the look of evil in your eyes youve been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16621</th>\n",
       "      <td>some sunny day baby when everything seems ok b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17852</th>\n",
       "      <td>thats word we pray pray pray we got to pray ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16903</th>\n",
       "      <td>told me that you loved me said that your love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>know you are a friend of mine babe you been go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             single_text\n",
       "9465   i see the look of evil in your eyes youve been...\n",
       "16621  some sunny day baby when everything seems ok b...\n",
       "17852  thats word we pray pray pray we got to pray ju...\n",
       "16903  told me that you loved me said that your love ...\n",
       "7079   know you are a friend of mine babe you been go..."
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.join(df.apply(split_text, axis = 1))\n",
    "df.drop('lyrics', axis = 1, inplace = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ac8f174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['single_text'].str.cat(sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f77d71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of non-English characters\n",
    "regex = re.compile('[^a-zA-Z0-9]')\n",
    "text = regex.sub(' ', text)\n",
    "text = text.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d4bca2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9465</th>\n",
       "      <td>i see the look of evil in your eyes youve been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16621</th>\n",
       "      <td>some sunny day baby when everything seems ok b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17852</th>\n",
       "      <td>thats word we pray pray pray we got to pray ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16903</th>\n",
       "      <td>told me that you loved me said that your love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>know you are a friend of mine babe you been go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>sometimes i really think im going crazy in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18773</th>\n",
       "      <td>well baby used to stay out all night long she ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20074</th>\n",
       "      <td>we were just kids playin in the rain when you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>youre an anchor im uptight youre what gets me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>sometimes i wonder  do you even recognize the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             single_text\n",
       "9465   i see the look of evil in your eyes youve been...\n",
       "16621  some sunny day baby when everything seems ok b...\n",
       "17852  thats word we pray pray pray we got to pray ju...\n",
       "16903  told me that you loved me said that your love ...\n",
       "7079   know you are a friend of mine babe you been go...\n",
       "...                                                  ...\n",
       "8185   sometimes i really think im going crazy in the...\n",
       "18773  well baby used to stay out all night long she ...\n",
       "20074  we were just kids playin in the rain when you ...\n",
       "12838  youre an anchor im uptight youre what gets me ...\n",
       "1858   sometimes i wonder  do you even recognize the ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['single_text'] = text\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2e16509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate' : 0.01,\n",
    "          'input_seq' : 200,\n",
    "          'batch_size' : 64,\n",
    "          'epochs' : 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "43c14851",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltext = ''.join(df['single_text'])\n",
    "vocabulary = sorted(set(alltext))\n",
    "\n",
    "char_to_idx = {u:i for i, u in enumerate(vocabulary)}\n",
    "idx_to_char = np.array(vocabulary)\n",
    "\n",
    "text_ints = np.array([char_to_idx[c] for c in alltext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "43a5f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data = tf.data.Dataset.from_tensor_slices(text_ints)\n",
    "seq_length = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9ad99c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "15657692",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = character_data.batch(seq_length + 1, drop_remainder = True)\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ad3ef867",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(12000).batch(params['batch_size'], drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5a4059ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.lin = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.lin(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c9a0029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, network, optimizer, loss_fn, epochs):\n",
    "        self.network = network\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def fit(self, dataloader):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "\n",
    "                pred, hidden = self.network(x, None)\n",
    "                loss = self.loss_fn(pred, y)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            print(f'epoch {epoch}, loss {loss}')\n",
    "\n",
    "        return self.network, loss\n",
    "\n",
    "    def predict(self, *args, **kwargs):\n",
    "        return self.network(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6b575cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lyrics_dataset(Dataset):\n",
    "    def __init__(self, dat, vocab):\n",
    "        self.data = dat\n",
    "        self.vectorizer = CountVectorizer(vocabulary = vocab, stop_words = None)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.iloc[index]['single_text']\n",
    "        vector = self.vectorizer.transform([text])\n",
    "        return vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5a47aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = lyrics_dataset(train_data, vocabulary)\n",
    "test_set = lyrics_dataset(test_data, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a127af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_set, batch_size = params['batch_size'], shuffle = True)\n",
    "testloader = DataLoader(test_set, batch_size = params['batch_size'], shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e8c51932",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(vocabulary)\n",
    "hidden_size = 256\n",
    "output_size = len(vocabulary)\n",
    "\n",
    "network = RNN(input_size, hidden_size, output_size)\n",
    "model = Model(network, optimizer, F.cross_entropy, epochs = params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a96f1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy\n",
    "optimizer = optim.Adam(network.parameters(), lr = params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "73462aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not tensorflow.python.framework.ops.EagerTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[255], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[249], line 12\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m---> 12\u001b[0m         pred, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(pred, y)\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[248], line 9\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, hidden):\n\u001b[1;32m----> 9\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embedded, hidden)\n\u001b[0;32m     11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(output)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2195\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not tensorflow.python.framework.ops.EagerTensor"
     ]
    }
   ],
   "source": [
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820f263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
